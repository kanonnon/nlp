{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 62101046 雨宮佳音 自然言語処理レポート課題"
      ],
      "metadata": {
        "id": "_btsFpOF4U66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 準備\n",
        "必要なライブラリをインストール・インポートする"
      ],
      "metadata": {
        "id": "tmxsHpoachw-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGvqw20gcNYP",
        "outputId": "8c6d3096-8db7-4715-cbb1-f8a64790cd2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 品詞のタグ付け\n",
        "ある文章のそれぞれのトークンに品詞を割り当てるタスクを考える。ここでは5種類のタガーをそれぞれ評価することで、優れたタグ付け方法を模索する。\n",
        "\n",
        "### 2-1. 準備"
      ],
      "metadata": {
        "id": "xbBGN1F6d2FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from nltk.metrics import precision, recall, f_measure\n",
        "nltk.download('brown')\n",
        "\n",
        "# 文章と正解データの準備\n",
        "sentences = brown.sents(categories=\"news\")\n",
        "tagged_sentences = brown.tagged_sents(categories=\"news\")\n",
        "\n",
        "# 品詞を比較して評価する関数\n",
        "def evaluate_tagger(tagger, sentences, tagged_sentences):\n",
        "    predicted_tags = [tagger.tag(sent) for sent in sentences]\n",
        "    reference_tags = [[tag for (word, tag) in tagged_sent] for tagged_sent in tagged_sentences]\n",
        "    print(\"予測データの一部: \", predicted_tags[0])\n",
        "    print(\"正解データの一部: \", reference_tags[0])\n",
        "\n",
        "    # 品詞の一致数を計算\n",
        "    correct_tags = sum(sum(1 for (predicted_word, predicted_tag), reference_tag in zip(predicted_sent, reference_sent) if predicted_tag == reference_tag)\n",
        "                  for predicted_sent, reference_sent in zip(predicted_tags, reference_tags))\n",
        "\n",
        "\n",
        "    # 評価を計算\n",
        "    total_tags = sum(len(tags) for tags in reference_tags)\n",
        "    predicted_tags_flat = [tag for sent in predicted_tags for _, tag in sent]\n",
        "    reference_tags_flat = [tag for sent in reference_tags for tag in sent]\n",
        "\n",
        "    accuracy = correct_tags / total_tags\n",
        "    precision_score = precision(set(predicted_tags_flat), set(reference_tags_flat))\n",
        "    recall_score = recall(set(predicted_tags_flat), set(reference_tags_flat))\n",
        "    f_measure_score = f_measure(set(predicted_tags_flat), set(reference_tags_flat))\n",
        "\n",
        "    print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "    print(\"Precision: {:.4f}\".format(precision_score))\n",
        "    print(\"Recall: {:.4f}\".format(recall_score))\n",
        "    print(\"F-measure: {:.4f}\".format(f_measure_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkpOmyaxeuhm",
        "outputId": "22e99633-5f27-4a90-d61c-a6fb085bbd35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. デフォルトタガー\n",
        "デフォルトタガーとは、すべてのトークンに同じタグをつけるタグ付け方式である。\n",
        "タグ付きコーパスから最頻出の品詞を調べ、それをすべての単語に適用する。"
      ],
      "metadata": {
        "id": "R_thP_86frlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# default_taggerを用意\n",
        "tags = [tag for (word, tag) in brown.tagged_words(categories=\"news\")]\n",
        "most_frequent_tag = nltk.FreqDist(tags).max()\n",
        "default_tagger = nltk.DefaultTagger(most_frequent_tag)\n",
        "\n",
        "# 評価を実行\n",
        "evaluate_tagger(default_tagger, sentences, tagged_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b9rrWB2eBHk",
        "outputId": "e75e6f8f-6c44-4623-cbd0-0ef6b205822a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "予測データの一部:  [('The', 'NN'), ('Fulton', 'NN'), ('County', 'NN'), ('Grand', 'NN'), ('Jury', 'NN'), ('said', 'NN'), ('Friday', 'NN'), ('an', 'NN'), ('investigation', 'NN'), ('of', 'NN'), (\"Atlanta's\", 'NN'), ('recent', 'NN'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'NN'), ('``', 'NN'), ('no', 'NN'), ('evidence', 'NN'), (\"''\", 'NN'), ('that', 'NN'), ('any', 'NN'), ('irregularities', 'NN'), ('took', 'NN'), ('place', 'NN'), ('.', 'NN')]\n",
            "正解データの一部:  ['AT', 'NP-TL', 'NN-TL', 'JJ-TL', 'NN-TL', 'VBD', 'NR', 'AT', 'NN', 'IN', 'NP$', 'JJ', 'NN', 'NN', 'VBD', '``', 'AT', 'NN', \"''\", 'CS', 'DTI', 'NNS', 'VBD', 'NN', '.']\n",
            "Accuracy: 0.1309\n",
            "Precision: 0.0046\n",
            "Recall: 1.0000\n",
            "F-measure: 0.0091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "当然、評価は低く、精度は13.09%であった。予測データの一部を見ると、すべての単語に「NN」が適用されていることがわかる。つまり、文章全体の品詞のうち「NN」が最頻出で13.09%もを占めていることがわかる。正解値が「NN」であるものをすべて再現できていることから、再現率は100%となっている。"
      ],
      "metadata": {
        "id": "d3cRrZSDvlZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-3. 正規表現タガー\n",
        "正規表現タガーとは、パターンマッチに基づくタグ付け方法である。正規表現で単語の語尾を指定し、それに当てはまれば該当の品詞を振る。"
      ],
      "metadata": {
        "id": "z0kuwrikw5pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"参考書の記述に沿ったパターン\")\n",
        "\n",
        "# regexp_tagger_1を用意\n",
        "patterns_1 = [\n",
        "    (r\".*ing$\", \"VBG\"),\n",
        "    (r\".*ed$\", \"VBD\"),\n",
        "    (r\".*es$\", \"VBZ\"),\n",
        "    (r\".*ould$\", \"MD\"),\n",
        "    (r\".*\\'s$\", \"NN$\"),\n",
        "    (r\".*s$\", \"NNS\"),\n",
        "    (r\"^-?[0-9]+(.[0-9]+)?$\", \"CD\"),\n",
        "    (r\".*\", \"NN\")\n",
        "]\n",
        "regexp_tagger_1 = nltk.RegexpTagger(patterns_1)\n",
        "\n",
        "# 評価を実行\n",
        "evaluate_tagger(regexp_tagger_1, sentences, tagged_sentences)\n",
        "\n",
        "print(\"上記に自分で追加したパターン\")\n",
        "\n",
        "# regexp_tagger_2を用意\n",
        "patterns_2 = [\n",
        "    (r\"^([A-Z][a-z]+\\.?)+$\", \"NNP\"),  # 固有名詞\n",
        "    (r\"^-?[0-9]+(.[0-9]+)?$\", \"CD\"),  # 数字\n",
        "    (r\".*s$\", \"NNS\"),  # 複数形名詞\n",
        "    (r\".*ing$\", \"VBG\"),  # 動詞の進行形\n",
        "    (r\".*ed$\", \"VBD\"),  # 動詞の過去形\n",
        "    (r\".*es$\", \"VBZ\"),  # 動詞の三人称単数現在形\n",
        "    (r\".*ould$\", \"MD\"),  # 助動詞\n",
        "    (r\".*\\'s$\", \"NN$\"),  # 名詞所有格\n",
        "    (r\".*ment$\", \"NN\"),  # 名詞の語尾「ment」\n",
        "    (r\".*ful$\", \"JJ\"),  # 形容詞の語尾「ful」\n",
        "    (r\".*ly$\", \"RB\"),  # 副詞の語尾「ly」\n",
        "    (r\".*\", \"NN\")  # デフォルトの名詞\n",
        "]\n",
        "regexp_tagger_2 = nltk.RegexpTagger(patterns_2)\n",
        "\n",
        "# 評価を実行\n",
        "evaluate_tagger(regexp_tagger_2, sentences, tagged_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaqtwvGFxhlC",
        "outputId": "f535d23b-a8ba-477e-bd80-e925cfa1ac0c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "参考書の記述に沿ったパターン\n",
            "予測データの一部:  [('The', 'NN'), ('Fulton', 'NN'), ('County', 'NN'), ('Grand', 'NN'), ('Jury', 'NN'), ('said', 'NN'), ('Friday', 'NN'), ('an', 'NN'), ('investigation', 'NN'), ('of', 'NN'), (\"Atlanta's\", 'NN$'), ('recent', 'NN'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', 'NN'), ('no', 'NN'), ('evidence', 'NN'), (\"''\", 'NN'), ('that', 'NN'), ('any', 'NN'), ('irregularities', 'VBZ'), ('took', 'NN'), ('place', 'NN'), ('.', 'NN')]\n",
            "正解データの一部:  ['AT', 'NP-TL', 'NN-TL', 'JJ-TL', 'NN-TL', 'VBD', 'NR', 'AT', 'NN', 'IN', 'NP$', 'JJ', 'NN', 'NN', 'VBD', '``', 'AT', 'NN', \"''\", 'CS', 'DTI', 'NNS', 'VBD', 'NN', '.']\n",
            "Accuracy: 0.2033\n",
            "Precision: 0.0367\n",
            "Recall: 1.0000\n",
            "F-measure: 0.0708\n",
            "上記に自分で追加したパターン\n",
            "予測データの一部:  [('The', 'NNP'), ('Fulton', 'NNP'), ('County', 'NNP'), ('Grand', 'NNP'), ('Jury', 'NNP'), ('said', 'NN'), ('Friday', 'NNP'), ('an', 'NN'), ('investigation', 'NN'), ('of', 'NN'), (\"Atlanta's\", 'NNS'), ('recent', 'NN'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', 'NN'), ('no', 'NN'), ('evidence', 'NN'), (\"''\", 'NN'), ('that', 'NN'), ('any', 'NN'), ('irregularities', 'NNS'), ('took', 'NN'), ('place', 'NN'), ('.', 'NN')]\n",
            "正解データの一部:  ['AT', 'NP-TL', 'NN-TL', 'JJ-TL', 'NN-TL', 'VBD', 'NR', 'AT', 'NN', 'IN', 'NP$', 'JJ', 'NN', 'NN', 'VBD', '``', 'AT', 'NN', \"''\", 'CS', 'DTI', 'NNS', 'VBD', 'NN', '.']\n",
            "Accuracy: 0.2158\n",
            "Precision: 0.0367\n",
            "Recall: 0.8889\n",
            "F-measure: 0.0705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "デフォルトタガーが13.09%だったのに対し、正規表現タガーでは精度が上がった。参考書に書いてあるパターンをそのまま記述した場合20.33%、パターンを追加したり順序を変更したりした場合21.58%になった。自分で追加したパターンには、固有名詞、名詞「ment」、形容詞「ful」、副詞「ly」を追加した。順序については、固有名詞や数字など特殊なパターンを先に配置し、一般的なパターンを後に置くことで、特殊なパターンがより一般的なパターンに優先されることを防いだ。ただし、再現率が大きく下がっていることに注意する。条件を細かくしたことで、本来より一般的な品詞としてタグづけされるべきであったトークンが、途中で誤って拾われたと考える。F値が僅かに下がっているため、必ずしも良いタガーになったとは言えない。"
      ],
      "metadata": {
        "id": "ISlseq5U8Abo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-4. ユニグラムタガー\n",
        "ユニグラムタガーとは、各トークンについて、そのトークンに対して最も多く付けられている品詞をあてるタグ付け方法である。これ以降では「tagged_sentences」を訓練集合とテスト集合に分けて、テスト集合において評価をするため、上2つのタガーとは評価基準が異なることに注意する。"
      ],
      "metadata": {
        "id": "EfJuUIXsDXqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unigram_taggerを用意\n",
        "size = int(len(tagged_sentences) * 0.9)\n",
        "train_sentences = tagged_sentences[:size]\n",
        "test_tagged_sentences = tagged_sentences[size:]\n",
        "test_sentences = sentences[size:]\n",
        "unigram_tagger = nltk.UnigramTagger(train_sentences)\n",
        "\n",
        "# 評価を実行\n",
        "evaluate_tagger(unigram_tagger, test_sentences, test_tagged_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5SYRnW2H2t_",
        "outputId": "a16f45ab-20f6-4450-d1d2-b6fadc8385ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "予測データの一部:  [('But', 'CC'), ('in', 'IN'), ('all', 'ABN'), ('its', 'PP$'), ('175', None), ('years', 'NNS'), (',', ','), ('not', '*'), ('a', 'AT'), ('single', 'AP'), ('Negro', 'NP'), ('student', 'NN'), ('has', 'HVZ'), ('entered', 'VBD'), ('its', 'PP$'), ('classrooms', None), ('.', '.')]\n",
            "正解データの一部:  ['CC', 'IN', 'ABN', 'PP$', 'CD', 'NNS', ',', '*', 'AT', 'AP', 'NP', 'NN', 'HVZ', 'VBN', 'PP$', 'NNS', '.']\n",
            "Accuracy: 0.8121\n",
            "Precision: 0.7479\n",
            "Recall: 0.9468\n",
            "F-measure: 0.8357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "81.21%という非常に高い精度になった。つまり、81.21%のトークンは、そのトークンの最頻出品詞として使われていることがわかる。ユニグラムに基づいたダグ付けの訓練では、現在処理しているトークンだけを、その他の文脈からは分離して考える。そのため、「wind」のように名詞にも動詞にもなりうる単語は、「the wind」であっても「to wind」であっても、同じタグをつけてしまう。そこで、前の単語の品詞の情報をもとに文脈を考慮できるようバイグラムタガーを考える。"
      ],
      "metadata": {
        "id": "OVRIuUVpNdt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-5. バイグラムタガー\n",
        "バイグラムタガーとは、現在処理しているトークンとその1つ前のトークンとの組み合わせに対して、最も多く付けられている品詞をあてるタグ付け方法である。文脈を考慮できるため、「wind」などの区別もできるようになり、ユニグラムタガーより精度が高くなる。"
      ],
      "metadata": {
        "id": "gr49WsZoPyYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bigram_taggerを用意\n",
        "bigram_tagger = nltk.BigramTagger(train_sentences)\n",
        "\n",
        "# 評価を実行\n",
        "evaluate_tagger(bigram_tagger, test_sentences, test_tagged_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE6o2tIhREZy",
        "outputId": "f6866c9a-8dc4-4633-e424-fddc27d0394e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "予測データの一部:  [('But', 'CC'), ('in', 'IN'), ('all', 'ABN'), ('its', 'PP$'), ('175', None), ('years', None), (',', None), ('not', None), ('a', None), ('single', None), ('Negro', None), ('student', None), ('has', None), ('entered', None), ('its', None), ('classrooms', None), ('.', None)]\n",
            "正解データの一部:  ['CC', 'IN', 'ABN', 'PP$', 'CD', 'NNS', ',', '*', 'AT', 'AP', 'NP', 'NN', 'HVZ', 'VBN', 'PP$', 'NNS', '.']\n",
            "Accuracy: 0.1021\n",
            "Precision: 0.5714\n",
            "Recall: 0.9577\n",
            "F-measure: 0.7158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "精度が10.21%という非常に低い結果になってしまった。原因は、予測データの一部を見ればわかる通り、「175」というトークン以降、この1文すべてのトークンの品詞が「None」となっていることである。バイグラムタガーは未知の単語に出会うと、タグ付けを行うことができない。そして、それに続く単語について、それ自身が未知でない場合でも直前が「None」であることから予測できていない。なぜなら、直前に「None」のあるケースが訓練されていないからである。この連鎖が1文の中で最後まで続くため、結果として精度が低くなった。"
      ],
      "metadata": {
        "id": "gMLmc2DVRvLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-6. 組み合わせタガー\n",
        "より精度の高いアルゴリズムを使えるときは使い、必要な時にはより適用範囲の広いアルゴリズムにフォールバックする方法である。ここでは参考書にあった「バイグラムタガー＆ユニグラムタガー＆デフォルトタガー」に加え、「トライグラムタガー＆バイグラムタガー＆ユニグラムタガー&正規表現タガー」を実装する。前者の例では、初めにバイグラムタガーを使ってトークンのタグ付けをし、それではタグが発見できなかった場合はユニグラムタガーを使い、それでも発見できなかった場合はデフォルトタガーを使うと言う仕組みである。"
      ],
      "metadata": {
        "id": "JwN7JqwOTEBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"参考書の記述に沿った組み合わせ\")\n",
        "\n",
        "# combination_taggerを用意\n",
        "combination_tagger_1 = nltk.UnigramTagger(train_sentences, backoff=default_tagger)\n",
        "combination_tagger_2 = nltk.BigramTagger(train_sentences, backoff=combination_tagger_1)\n",
        "\n",
        "# 評価を実行\n",
        "evaluate_tagger(combination_tagger_2, test_sentences, test_tagged_sentences)\n",
        "\n",
        "print(\"自分で考えた組み合わせ\")\n",
        "# combination_taggerを用意\n",
        "combination_tagger_1 = nltk.UnigramTagger(train_sentences, backoff=regexp_tagger_2)\n",
        "combination_tagger_2 = nltk.BigramTagger(train_sentences, backoff=combination_tagger_1)\n",
        "combination_tagger_3 = nltk.TrigramTagger(train_sentences, backoff=combination_tagger_2)\n",
        "\n",
        "# 評価を実行\n",
        "evaluate_tagger(combination_tagger_2, test_sentences, test_tagged_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7eDlSfzUMBi",
        "outputId": "31fa0bce-08e2-4b01-a8a0-b98955d049ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "参考書の記述に沿った組み合わせ\n",
            "予測データの一部:  [('But', 'CC'), ('in', 'IN'), ('all', 'ABN'), ('its', 'PP$'), ('175', 'NN'), ('years', 'NNS'), (',', ','), ('not', '*'), ('a', 'AT'), ('single', 'AP'), ('Negro', 'NP'), ('student', 'NN'), ('has', 'HVZ'), ('entered', 'VBD'), ('its', 'PP$'), ('classrooms', 'NN'), ('.', '.')]\n",
            "正解データの一部:  ['CC', 'IN', 'ABN', 'PP$', 'CD', 'NNS', ',', '*', 'AT', 'AP', 'NP', 'NN', 'HVZ', 'VBN', 'PP$', 'NNS', '.']\n",
            "Accuracy: 0.8452\n",
            "Precision: 0.7983\n",
            "Recall: 0.9500\n",
            "F-measure: 0.8676\n",
            "自分で考えた組み合わせ\n",
            "予測データの一部:  [('But', 'CC'), ('in', 'IN'), ('all', 'ABN'), ('its', 'PP$'), ('175', 'CD'), ('years', 'NNS'), (',', ','), ('not', '*'), ('a', 'AT'), ('single', 'AP'), ('Negro', 'NP'), ('student', 'NN'), ('has', 'HVZ'), ('entered', 'VBD'), ('its', 'PP$'), ('classrooms', 'NNS'), ('.', '.')]\n",
            "正解データの一部:  ['CC', 'IN', 'ABN', 'PP$', 'CD', 'NNS', ',', '*', 'AT', 'AP', 'NP', 'NN', 'HVZ', 'VBN', 'PP$', 'NNS', '.']\n",
            "Accuracy: 0.8725\n",
            "Precision: 0.7983\n",
            "Recall: 0.9406\n",
            "F-measure: 0.8636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "タガーを組み合わせて受け皿を作ることにより、バイグラムのみのときの欠点を解消できた。参考書に沿った組み合わせでは84.52%、自分で考えた組み合わせでは87.25%の精度を出すことができた。後者ではトライグラムを使うことで、2トークンの文脈からは推定できなかった品詞を、3トークンの文脈から正しく判断できるようになった。また、最下位のバックオフとして正規表現タガーを使うことで、例えば予測データの「175」を正しく判断できるようになった。"
      ],
      "metadata": {
        "id": "eI1fdV9aXDBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 文章のチャンキング\n",
        "1つの文章を複数のトークンで構成されたテキスト断片に分割し、ラベル付けすることをチャンキングという。ここでは5種類のチャンカをそれぞれ評価することで、優れたタグ付け方法を模索する。\n",
        "### 3-1. チャンキングの視覚的理解\n",
        "ここでは、最も単純なNPチャンクを実装し、視覚的に理解を深める。"
      ],
      "metadata": {
        "id": "4J6t3xkCZlaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [(\"the\", \"DT\"), (\"litte\", \"JJ\"), (\"yello\", \"JJ\"), (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
        "grammer = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp = nltk.RegexpParser(grammer)\n",
        "print(cp.parse(sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Wku3IzNfopi",
        "outputId": "8070f681-9003-48d2-b182-9a004d8ebea9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP the/DT litte/JJ yello/JJ dog/NN)\n",
            "  barked/VBD\n",
            "  at/IN\n",
            "  (NP the/DT cat/NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![名詞句チャンキングの構造木](https://drive.google.com/uc?id=1W3uv5ATlu9xV1KcwEihRlE5iA03E0-vt)  \n",
        "\n",
        "ここでは、1つの正規表現のルールで構成された単純なチャンク文法を使っている。このルールにおいてNPチャンクは、省略可能な限定詞（DT）に続いて任意の数の形容詞（JJ）が出現し、最後に名詞（NN）が来るものと定義されている。  \n",
        "\n",
        "次に2つのルールで構成されるNPチャンクを実装する。"
      ],
      "metadata": {
        "id": "Hqqzf1ytgjz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"), (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"gorlden\", \"JJ\"), (\"hair\", \"NN\")]\n",
        "grammer = r\"\"\"\n",
        "    NP: {<DT|PP\\$>?<JJ>*<NN>}\n",
        "        {<NNP>+}\n",
        "\"\"\"\n",
        "cp = nltk.RegexpParser(grammer)\n",
        "print(cp.parse(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrCXSd_GjPCE",
        "outputId": "748f639e-8498-4b98-c59d-57e05f2f08b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP Rapunzel/NNP)\n",
            "  let/VBD\n",
            "  down/RP\n",
            "  (NP her/PP$ long/JJ gorlden/JJ hair/NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![名詞句チャンキングの構造木](https://drive.google.com/uc?id=1iHCyGjacg99UmWgUYrNOlHKP5XenVUvk)  \n",
        "\n",
        "1つ目のルールにおいては、NPチャンクは、0あるいは1個の限定詞もしくは所有代名詞、0個以上の形容詞、1つの名詞だと定義づけられている。2つ目のルールにおいては、1つ以上の固有名詞だと定義づけられている。"
      ],
      "metadata": {
        "id": "CcV7rRnEk1pt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2. IOBタグ\n",
        "IOBタグによって、それぞれのトークンはI(inside)、O(outside)、B(begin)と言う3つの特殊なチャンクダグが付けられる。チャンクの先頭に存在するトークンにはB、それに続くチャンク内にあるトークンにはI、それ以外のチャンク外のトークンにはOというタグが付けられる。BとIのタグには、B-NP、I-NPのように、チャンクタイプが接尾辞として付けられる。"
      ],
      "metadata": {
        "id": "oqiFFdnQmzyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-3. 準備"
      ],
      "metadata": {
        "id": "hKckWzWHouc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import conll2000\n",
        "nltk.download('conll2000')\n",
        "\n",
        "# データの準備\n",
        "train_sentences = conll2000.chunked_sents(\"test.txt\", chunk_types=[\"NP\"])\n",
        "test_sentences = conll2000.chunked_sents(\"test.txt\", chunk_types=[\"NP\"])\n",
        "postags = sorted(set(pos for sent in train_sentences\n",
        "                    for (word, pos) in sent.leaves()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDvlwza1pr5m",
        "outputId": "c50e8cd0-3299-4380-a5f8-b09715f52e7b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-4. 最も単純なチャンカ\n",
        "「nltk.RegexpParser()」の引数に何も指定せずに、全くチャンクを生成しないチャンカを作成した。"
      ],
      "metadata": {
        "id": "xFP9PkSbvQeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cp = nltk.RegexpParser(\"\")\n",
        "\n",
        "print(cp.evaluate(test_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khD-YDITvQ04",
        "outputId": "14bc9eae-2ae5-4a8a-a29a-3e4948089aa5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-78ee0edddd02>:3: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(cp.evaluate(test_sentences))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChunkParse score:\n",
            "    IOB Accuracy:  43.4%%\n",
            "    Precision:      0.0%%\n",
            "    Recall:         0.0%%\n",
            "    F-Measure:      0.0%%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このチャンカがチャンキングを全く行わないことから、「IOB Accuracy:  43.4%」と言う結果は、43.4%の単語にOのタグが付けられており、それらがNPチャンクではないことを表す。そして、このチャンカはチャンクを全く見つけることができないため、適応率、再現率、F値はいずれも0になる。"
      ],
      "metadata": {
        "id": "yGD2uxXN0Ymo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-5. 単純な正規表現チャンカ\n",
        "名詞句タグを特徴的に表す文字で始まるタグを発見する単純な正規表現チャンカを作成した。"
      ],
      "metadata": {
        "id": "N-M-lWBM2qqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammer = r\"NP: {<[CDJNP].*>+}\"\n",
        "cp = nltk.RegexpParser(grammer)\n",
        "\n",
        "print(cp.evaluate(test_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3cA6_H_y_i0",
        "outputId": "eecdda95-f948-40d4-c3ec-4d80c408f857"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-2a230905174b>:4: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(cp.evaluate(test_sentences))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChunkParse score:\n",
            "    IOB Accuracy:  87.7%%\n",
            "    Precision:     70.6%%\n",
            "    Recall:        67.8%%\n",
            "    F-Measure:     69.2%%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "「<[CDJNP].*>+」より、「C」「D」「J」「N」「P」のいずれかの品詞タグから始まる単語の、1回以上の繰り返しで構成される名詞句をチャンク化する。非常に簡単な正規表現しか使っていないが、比較的高い精度を出すことがわかる。一方で、適合率と再現率の低さから、一部の名詞句を見逃していたり、誤った部分もチャンクとして予測したりする箇所が多いことがわかる。"
      ],
      "metadata": {
        "id": "1HCuOkMQ27Zs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-6. ユニグラムタガーを用いた名詞句チャンカ\n",
        "訓練コーパスを利用してそれぞれの品詞タグに最も適切なチャンクタグを探すため、ユニグラムタガーを用いる。このユニグラムタガーは、それぞれの単語の正しい品詞タグを決定するのではなく、品詞タグを与えて正しいチャンクタグを決定するものである。"
      ],
      "metadata": {
        "id": "bXLTsUab4O-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnigramChunker(nltk.ChunkParserI):\n",
        " def __init__(self, train_sents):\n",
        "   train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)] \n",
        "                 for sent in train_sents]\n",
        "   self.tagger = nltk.UnigramTagger(train_data)\n",
        "\n",
        " def parse(self, sentence):\n",
        "   pos_tags = [pos for (word,pos) in sentence]\n",
        "   tagged_pos_tags = self.tagger.tag(pos_tags)\n",
        "   chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
        "   conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
        "                in zip(sentence, chunktags)] \n",
        "   return nltk.chunk.conlltags2tree(conlltags)\n",
        "\n",
        "unigram_chunker = UnigramChunker(train_sentences)\n",
        "print(unigram_chunker.evaluate(test_sentences))\n",
        "print(unigram_chunker.tagger.tag(postags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob-zbXFv5FXj",
        "outputId": "24569f74-60a0-4171-b784-0895ae148604"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-095b0c03af83>:16: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(unigram_chunker.evaluate(test_sentences))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChunkParse score:\n",
            "    IOB Accuracy:  92.9%%\n",
            "    Precision:     79.9%%\n",
            "    Recall:        86.8%%\n",
            "    F-Measure:     83.2%%\n",
            "[('#', 'B-NP'), ('$', 'B-NP'), (\"''\", 'O'), ('(', 'O'), (')', 'O'), (',', 'O'), ('.', 'O'), (':', 'O'), ('CC', 'O'), ('CD', 'I-NP'), ('DT', 'B-NP'), ('EX', 'B-NP'), ('FW', 'I-NP'), ('IN', 'O'), ('JJ', 'I-NP'), ('JJR', 'B-NP'), ('JJS', 'I-NP'), ('MD', 'O'), ('NN', 'I-NP'), ('NNP', 'I-NP'), ('NNPS', 'I-NP'), ('NNS', 'I-NP'), ('PDT', 'I-NP'), ('POS', 'B-NP'), ('PRP', 'B-NP'), ('PRP$', 'B-NP'), ('RB', 'O'), ('RBR', 'O'), ('RBS', 'B-NP'), ('RP', 'O'), ('TO', 'O'), ('UH', 'B-NP'), ('VB', 'O'), ('VBD', 'O'), ('VBG', 'O'), ('VBN', 'O'), ('VBP', 'O'), ('VBZ', 'O'), ('WDT', 'B-NP'), ('WP', 'B-NP'), ('WP$', 'B-NP'), ('WRB', 'O'), ('``', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "正規表現チャンカではF値が69.2%だったが、今回は83.2%まで上昇した。再現率が特に高くなっている。訓練コーパスから単語の品詞タグとチャンクタグの関連性を学習することで、与えられた品詞タグから、その品詞に対して適切なチャンクタグを予測できた。また、出力されたタグのペアを見ると、句読点はチャンクの外にあり、NPチャンクに含まれる品詞はほとんどが名詞であり、限定詞や所有格からNPチャンクが始まることを確認できる。ただし、単語単体での情報に依存しているため、文脈や依存関係などのより高度な言語特徴を考慮することはできない。そこで、バイグラムタガーを用いる。"
      ],
      "metadata": {
        "id": "GyuKxepr61u4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-7. バイグラムタガーを用いた名詞句チャンカ\n"
      ],
      "metadata": {
        "id": "t2Sw7WJs_GU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramChunker(nltk.ChunkParserI):\n",
        " def __init__(self, train_sents):\n",
        "   train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)] \n",
        "                 for sent in train_sents]\n",
        "   self.tagger = nltk.BigramTagger(train_data)\n",
        "\n",
        " def parse(self, sentence):\n",
        "   pos_tags = [pos for (word,pos) in sentence]\n",
        "   tagged_pos_tags = self.tagger.tag(pos_tags)\n",
        "   chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
        "   conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
        "                in zip(sentence, chunktags)] \n",
        "   return nltk.chunk.conlltags2tree(conlltags)\n",
        "   \n",
        "bigram_chunker = BigramChunker(train_sentences)\n",
        "print(bigram_chunker.evaluate(test_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuYuqp6n_MZt",
        "outputId": "8d50112b-2036-4890-8d99-94b24f9df471"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-e55b2745ee29>:16: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(bigram_chunker.evaluate(test_sentences))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChunkParse score:\n",
            "    IOB Accuracy:  93.4%%\n",
            "    Precision:     82.6%%\n",
            "    Recall:        87.5%%\n",
            "    F-Measure:     85.0%%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "直線の単語を踏まえて文脈を考慮できるようになったことで、4つの評価値全てが上昇した。"
      ],
      "metadata": {
        "id": "IA1Weyljfsdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "今までのチャンカでは、品詞タグをもとにチャンクを生成していた。しかし、これではSVOO構文などを正確にチャンキングできない可能性がある。そこで、品詞タグを使うだけではなく、単語の内容に関する情報も使うことにする。\n",
        "\n",
        "### 3-8. 連続分類器を利用したチャンカ\n"
      ],
      "metadata": {
        "id": "kJ1Rg5LNf2_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "class ConsecutiveNPChunkTagger(nltk.TaggerI):\n",
        "\n",
        "    def __init__(self, train_sents):\n",
        "        train_set = []\n",
        "        for tagged_sent in train_sents:\n",
        "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
        "            history = []\n",
        "            for i, (word, tag) in enumerate(tagged_sent):\n",
        "                featureset = npchunk_features(untagged_sent, i, history)\n",
        "                train_set.append( (featureset, tag) )\n",
        "                history.append(tag)\n",
        "        self.classifier = nltk.MaxentClassifier.train(\n",
        "            train_set, algorithm='megam', trace=0)\n",
        "\n",
        "    def tag(self, sentence):\n",
        "        history = []\n",
        "        for i, word in enumerate(sentence):\n",
        "            featureset = npchunk_features(sentence, i, history)\n",
        "            tag = self.classifier.classify(featureset)\n",
        "            history.append(tag)\n",
        "        return zip(sentence, history)\n",
        "\n",
        "class ConsecutiveNPChunker(nltk.ChunkParserI):\n",
        "    def __init__(self, train_sents):\n",
        "        tagged_sents = [[((w,t),c) for (w,t,c) in\n",
        "                         nltk.chunk.tree2conlltags(sent)]\n",
        "                        for sent in train_sents]\n",
        "        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)\n",
        "\n",
        "    def parse(self, sentence):\n",
        "        tagged_sents = self.tagger.tag(sentence)\n",
        "        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]\n",
        "        return nltk.chunk.conlltags2tree(conlltags)\n",
        "\n",
        "def npchunk_features(sentence, i, history):\n",
        "    word, pos = sentence[i]\n",
        "    return {\"pos\": pos}\n",
        "\n",
        "chunker = ConsecutiveNPChunker(train_sentences)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "edRQ35XPisUJ",
        "outputId": "0db64346-4fdb-4608-a0c7-8931a91d12f1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass ConsecutiveNPChunkTagger(nltk.TaggerI):\\n\\n    def __init__(self, train_sents):\\n        train_set = []\\n        for tagged_sent in train_sents:\\n            untagged_sent = nltk.tag.untag(tagged_sent)\\n            history = []\\n            for i, (word, tag) in enumerate(tagged_sent):\\n                featureset = npchunk_features(untagged_sent, i, history)\\n                train_set.append( (featureset, tag) )\\n                history.append(tag)\\n        self.classifier = nltk.MaxentClassifier.train(\\n            train_set, algorithm=\\'megam\\', trace=0)\\n\\n    def tag(self, sentence):\\n        history = []\\n        for i, word in enumerate(sentence):\\n            featureset = npchunk_features(sentence, i, history)\\n            tag = self.classifier.classify(featureset)\\n            history.append(tag)\\n        return zip(sentence, history)\\n\\nclass ConsecutiveNPChunker(nltk.ChunkParserI):\\n    def __init__(self, train_sents):\\n        tagged_sents = [[((w,t),c) for (w,t,c) in\\n                         nltk.chunk.tree2conlltags(sent)]\\n                        for sent in train_sents]\\n        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)\\n\\n    def parse(self, sentence):\\n        tagged_sents = self.tagger.tag(sentence)\\n        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]\\n        return nltk.chunk.conlltags2tree(conlltags)\\n\\ndef npchunk_features(sentence, i, history):\\n    word, pos = sentence[i]\\n    return {\"pos\": pos}\\n\\nchunker = ConsecutiveNPChunker(train_sentences)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "参考書に沿って以上を実装してみたが\n",
        "```\n",
        "LookupError: \n",
        "NLTK was unable to find the megam file!\n",
        "Use software specific configuration parameters or set the MEGAM environment variable.\n",
        "```\n",
        "のエラーが出てしまった。おそらくPythonとNLTKのバージョンの違いが原因だと考える。使用しているバージョンに合わせた実装を調べるなどして試行錯誤したが、解決できなかった。\n",
        "\n"
      ],
      "metadata": {
        "id": "SMtXSK5WsI5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "これまでは様々な名詞句チャンカを見てきた。次は、名詞句・前置詞句・動詞句、そして文を扱うルールを構築する。\n",
        "\n",
        "### 3-9. NP, PP, VP, Sを扱うチャンカ\n",
        "新たにルールを追加し、実装は3-5と同じようにした。"
      ],
      "metadata": {
        "id": "eyDUQCcRszhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [(\"Mary\", \"NN\"), (\"saw\", \"VBD\"), (\"the\", \"DT\"), (\"cat\", \"NN\"), (\"sit\", \"VB\"), (\"on\", \"IN\"), (\"the\", \"DT\"), (\"mat\", \"NN\")]\n",
        "grammar = r\"\"\"\n",
        "    NP: {<DT|JJ|NN.*>+}\n",
        "    PP: {<IN><NP>}\n",
        "    VP: {<VB.*><NP|PP|CLAUSE>+$}\n",
        "    CLAUSE: {<NP><VP>}\n",
        "    \"\"\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "print(cp.parse(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRML6Ffltj-7",
        "outputId": "bfa9ffe9-e738-480e-e2e9-912ab04311cb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP Mary/NN)\n",
            "  saw/VBD\n",
            "  (CLAUSE\n",
            "    (NP the/DT cat/NN)\n",
            "    (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![チャンキングの構造木](https://drive.google.com/uc?id=15M5Z2HNrg7Al5mI8paIwCIIUQywqdPoK)  \n",
        "\n",
        "ここでは、sawから始まる動詞句を見逃してしまっている。そこで、すべてのパターンを試した後、チャンカがその処理を繰り返すようにする。"
      ],
      "metadata": {
        "id": "Izhl_f_iCu7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cp = nltk.RegexpParser(grammar, loop=2)\n",
        "print(cp.parse(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAkTapzzvCHx",
        "outputId": "2ec077bb-ed2d-412c-bec0-bea51a4f8c9e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (CLAUSE\n",
            "    (NP Mary/NN)\n",
            "    (VP\n",
            "      saw/VBD\n",
            "      (CLAUSE\n",
            "        (NP the/DT cat/NN)\n",
            "        (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![チャンキングの構造木](https://drive.google.com/uc?id=1J4ag1o3s1czZCGNIKy7WNJD78Q-783Pa)  \n"
      ],
      "metadata": {
        "id": "zJxzd7lODEmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1段階ではなく再帰的にルールを適用することで、見落としていた句を拾えるようになった。"
      ],
      "metadata": {
        "id": "iqRAka52GPdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 構文解析\n",
        "最後に、構文解析を扱う。ここでは、昨日の試験に登場した「John gave Susan a book in the room」という文について、試験と同じ文法ルールを用いて構文解析を行う。"
      ],
      "metadata": {
        "id": "AMvxS0CuIZE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-1. 異なる構文解析アルゴリズムの比較"
      ],
      "metadata": {
        "id": "Ad_CzFfTVPWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import CFG\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP | S PP\n",
        "    NP -> noun | det noun | NP PP\n",
        "    VP -> verb NP | verb NP NP | VP PP\n",
        "    PP -> prep NP\n",
        "    noun -> \"John\" | \"Susan\" | \"book\" | \"room\"\n",
        "    verb -> \"gave\"\n",
        "    det -> \"a\" | \"the\"\n",
        "    prep -> \"in\"\n",
        "\"\"\")\n",
        "sentence = 'John gave Susan a book in the room'.split()\n",
        "\n",
        "# parser = nltk.RecursiveDescentParser(grammar) # 再帰下降構文解析\n",
        "# parser = nltk.ShiftReduceParser(grammar) # Shift-Reduce構文解析\n",
        "parser = nltk.ChartParser(grammar) # チャート法構文解析\n",
        "\n",
        "for tree in parser.parse(sentence):\n",
        "  print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAFB4DIvI7e8",
        "outputId": "669c0128-720a-48aa-99f7-7e69a745334f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (S\n",
            "    (NP (noun John))\n",
            "    (VP (verb gave) (NP (noun Susan)) (NP (det a) (noun book))))\n",
            "  (PP (prep in) (NP (det the) (noun room))))\n",
            "(S\n",
            "  (NP (noun John))\n",
            "  (VP\n",
            "    (VP (verb gave) (NP (noun Susan)) (NP (det a) (noun book)))\n",
            "    (PP (prep in) (NP (det the) (noun room)))))\n",
            "(S\n",
            "  (NP (noun John))\n",
            "  (VP\n",
            "    (verb gave)\n",
            "    (NP (noun Susan))\n",
            "    (NP\n",
            "      (NP (det a) (noun book))\n",
            "      (PP (prep in) (NP (det the) (noun room))))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RecursiveDescentParser（再帰下降構文解析器）の場合、RecursionErrorとなってしまって、適切に構文解析ができなかった。再帰下降構文解析は、トップダウン方式で、文法の各規則に対して再帰的に呼び出される関数を用いて文を解析する。NP -> NP PPのような左再帰的なルールを用いると、バックトラックを繰り返し無限ループに陥ってしまう。今回のルールでは、NP -> NP PPとVP -> VP PPという2つの左再帰ルールがあり、再帰の無限ループによるエラーが起きてしまった。\n",
        "\n",
        "ShiftReduceParser（Shift-Reduce構文解析器）の場合、結果が何も表示されなかった。Shift-Reduce構文解析は、ボトムアップ方式で\n",
        "、スタックとトークン列の操作を用いて文を解析する。トークン列を先頭から順にスキャンし、スタック上でルールにマッチするかどうかをチェックする。ルールにマッチする場合、スタック上のトークンをルールの左辺に置き換え、ルールにマッチしない場合、スキャンしたトークンをスタックにプッシュする。このシフト（スキャン）、リデュース（置き換え）の操作を繰り返しながら解析を進める。ただし、行き止まりに達して構文木を見つけられなくなってしまう場合がある。なぜなら、構文解析器がより初期の段階でなされた選択を取り消すことができないからだ。今回のルールは結果が3つ表示される通り、曖昧な文法が含まれる。複数のルールが同時に適用可能な場合にどちらかを選択する必要があり、その結果行き止まりに達してしまったと考える。\n",
        "\n",
        "ChartParser（チャート構文解析器）の場合、望み通りの結果が得られた。チャート構文解析器は、ボトムアップの動的計画法に基づいた手法である。入力文をスキャンし、可能なすべての部分構文木を生成し、チャートと呼ばれるデータ構造に格納する。チャート内の部分構文木を組み合わせて、最終的な解析結果を得る。全体的な解析の効率性が高く、再帰深さの制限に対して頑健であることから、適切に解析できた。"
      ],
      "metadata": {
        "id": "p-izqcahf6vL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-2. 構文解析に確率を与える\n",
        "試験問題と同様、それぞれのルールに確率を与えた。確率値は基本的に試験問題と同じであるが、各品詞におけるある単語の確率は、その品詞全体で合計1にする必要があったため、適当に値を与えた。"
      ],
      "metadata": {
        "id": "pyLIQHDegBmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.grammar import PCFG\n",
        "from nltk.parse import pchart\n",
        "\n",
        "grammar = PCFG.fromstring(\"\"\"\n",
        "    S -> NP VP [0.6] | S PP [0.4]\n",
        "    NP -> noun [0.3] | det noun [0.5] | NP PP [0.2]\n",
        "    VP -> verb NP [0.5] | verb NP NP [0.4] | VP PP [0.1]\n",
        "    PP -> prep NP [1.0]\n",
        "    noun -> \"John\" [0.1] | \"Susan\" [0.1] | \"book\" [0.4] | \"room\" [0.4]\n",
        "    verb -> \"gave\" [1.0]\n",
        "    det -> \"a\" [0.5] | \"the\" [0.5]\n",
        "    prep -> \"in\" [1.0]\n",
        "\"\"\")\n",
        "parser = pchart.InsideChartParser(grammar)\n",
        "for tree in parser.parse(sentence):\n",
        "  print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdvfRLuJWefw",
        "outputId": "36f07a2d-e5d8-4eb8-fff6-7bcb525f9036"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (S\n",
            "    (NP (noun John))\n",
            "    (VP\n",
            "      (verb gave)\n",
            "      (NP (noun Susan))\n",
            "      (NP (det a) (noun book))))\n",
            "  (PP (prep in) (NP (det the) (noun room)))) (p=8.64e-07)\n",
            "(S\n",
            "  (NP (noun John))\n",
            "  (VP\n",
            "    (verb gave)\n",
            "    (NP (noun Susan))\n",
            "    (NP\n",
            "      (NP (det a) (noun book))\n",
            "      (PP (prep in) (NP (det the) (noun room)))))) (p=4.32e-07)\n",
            "(S\n",
            "  (NP (noun John))\n",
            "  (VP\n",
            "    (VP\n",
            "      (verb gave)\n",
            "      (NP (noun Susan))\n",
            "      (NP (det a) (noun book)))\n",
            "    (PP (prep in) (NP (det the) (noun room))))) (p=2.16e-07)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果として、「ジョンはこの部屋でスーザンに本をあげた」と訳されるような構文木の確率が最も高くなった。"
      ],
      "metadata": {
        "id": "O00q6HQthRKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-3. 適格部分文字列表の作成\n",
        "4-*1ではチャート構文解析器を用いて解析を行った。この解析器で用いる適格部分文字列表を、構文解析関数を使わずに実装した。*"
      ],
      "metadata": {
        "id": "w3qq7XFlqa_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_wfst(tokens, grammar):\n",
        "     numtokens = len(tokens)\n",
        "     wfst = [[None for i in range(numtokens+1)] for j in range(numtokens+1)]\n",
        "     for i in range(numtokens):\n",
        "         productions = grammar.productions(rhs=tokens[i])\n",
        "         wfst[i][i+1] = productions[0].lhs()\n",
        "     return wfst\n",
        "\n",
        "def complete_wfst(wfst, tokens, grammar, trace=False):\n",
        "     index = dict((p.rhs(), p.lhs()) for p in grammar.productions())\n",
        "     numtokens = len(tokens)\n",
        "     for span in range(2, numtokens+1):\n",
        "         for start in range(numtokens+1-span):\n",
        "             end = start + span\n",
        "             for mid in range(start+1, end):\n",
        "                 nt1, nt2 = wfst[start][mid], wfst[mid][end]\n",
        "                 if nt1 and nt2 and (nt1,nt2) in index:\n",
        "                     wfst[start][end] = index[(nt1,nt2)]\n",
        "                     if trace:\n",
        "                         print(\"[{}] {} [{}] {} [{}] ==> [{}] {} [{}]\".format(start, nt1, mid, nt2, end, start, index[(nt1,nt2)], end))\n",
        "     return wfst\n",
        "\n",
        "def display(wfst, tokens):\n",
        "    num_tokens = len(wfst) - 1\n",
        "\n",
        "    headers = ' '.join([(\"%-4d\" % i) for i in range(1, num_tokens + 1)])\n",
        "    print('WFST ' + headers)\n",
        "\n",
        "    for i in range(num_tokens):\n",
        "        row = \"{:<4d}\".format(i)\n",
        "        for j in range(1, num_tokens + 1):\n",
        "            cell = \"{}\".format(wfst[i][j] or '.')\n",
        "            row += \"{:<5s}\".format(cell)\n",
        "        print(row)\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP | S PP\n",
        "    NP -> noun | det noun | NP PP\n",
        "    VP -> verb NP | verb NP NP | VP PP\n",
        "    PP -> prep NP\n",
        "    noun -> \"John\" | \"Susan\" | \"book\" | \"room\"\n",
        "    verb -> \"gave\"\n",
        "    det -> \"a\" | \"the\"\n",
        "    prep -> \"in\"\n",
        "\"\"\")\n",
        "\n",
        "wfst0 = init_wfst(sentence, grammar)\n",
        "\n",
        "wfst1 = complete_wfst(wfst0, sentence, grammar)\n",
        "display(wfst1, sentence)\n",
        "\n",
        "wfst1 = complete_wfst(wfst0, sentence, grammar, trace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epK99EbaiSI5",
        "outputId": "8398d26b-c91d-4426-dcfb-ffca3289cf3e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WFST 1    2    3    4    5    6    7    8   \n",
            "0   noun .    .    .    .    .    .    .    \n",
            "1   .    verb .    .    .    .    .    .    \n",
            "2   .    .    noun .    .    .    .    .    \n",
            "3   .    .    .    det  NP   .    .    NP   \n",
            "4   .    .    .    .    noun .    .    .    \n",
            "5   .    .    .    .    .    prep .    PP   \n",
            "6   .    .    .    .    .    .    det  NP   \n",
            "7   .    .    .    .    .    .    .    noun \n",
            "[3] det [4] noun [5] ==> [3] NP [5]\n",
            "[6] det [7] noun [8] ==> [6] NP [8]\n",
            "[5] prep [6] NP [8] ==> [5] PP [8]\n",
            "[3] NP [5] PP [8] ==> [3] NP [8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[0] John [1] gave [2] Susan [3] a [4] book [5] in [6] the [7] room [8]  \n",
        "適格部分文字列表では、三角行列中のセルを埋めていくことによって単語の位置を記録する。縦軸は部分文字列の開始位置、横軸は終了位置を示す。結果として、例えば「gave」を表すverbは座標(1, 2)のセルに現れている。また、「a」を表すdetは座標(3, 4)に、「book」を表すnounは座標(4, 5)に現れている。そして、「a book」を表すNPは座標(3, 5)に現れている。一般化すると、生成規則A -> B Cがある時、非終端記号Bが(i, k)に、Cが(k, j)にある場合、Aは(i, j)に位置する。ただし、今回の実装方法では複数の解釈が得られる曖昧な文法を完全に再現することはできない。そのため、部分木は表現できているが、文章全体を表すSは表に出てこない。"
      ],
      "metadata": {
        "id": "qJ-e0OXWrlj7"
      }
    }
  ]
}